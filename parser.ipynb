{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa7f3d6",
      "metadata": {
        "id": "7fa7f3d6"
      },
      "outputs": [],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dc1afb",
      "metadata": {
        "id": "f5dc1afb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from requests.exceptions import TooManyRedirects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8967050d",
      "metadata": {
        "scrolled": true,
        "id": "8967050d"
      },
      "outputs": [],
      "source": [
        "# Инициализация веб-драйвера\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.executable_path = r\"Путь до chromedriver.exe\"\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Открытие страницы\n",
        "base_url = \"url сайта\"\n",
        "news_url = \"/news\"\n",
        "driver.get(base_url + news_url)\n",
        "\n",
        "# Парсинг ссылок и дат\n",
        "links = []\n",
        "dates = []\n",
        "click_counter = 0\n",
        "\n",
        "while click_counter < 100:\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "    articles = soup.find_all(\"div\", class_=\"post_item\")\n",
        "\n",
        "    for article in articles:\n",
        "        date_elem = article.find(\"span\", class_=\"post_date\")\n",
        "        if date_elem:\n",
        "            date_text = date_elem.get_text()\n",
        "            dates.append(date_text)\n",
        "        else:\n",
        "            dates.append(np.nan)\n",
        "        link_elem = article.find(\"a\", href=True)\n",
        "        link = link_elem[\"href\"] if link_elem else None\n",
        "        links.append(link)\n",
        "\n",
        "    try:\n",
        "        load_more_btn = driver.find_element(By.CLASS_NAME, \"load_more_btn\")\n",
        "        driver.execute_script(\"arguments[0].click();\", load_more_btn)\n",
        "        WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"post_item\"))\n",
        "        )\n",
        "        click_counter += 1\n",
        "    except Exception as e:\n",
        "        print(\"Ошибка при нажатии на кнопку:\", str(e))\n",
        "        break\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "# Создание DataFrame\n",
        "data = {\n",
        "    \"Ссылка\": links,\n",
        "    \"Дата\": dates\n",
        "}\n",
        "df_Chat = pd.DataFrame(data)\n",
        "\n",
        "# Фильтрация и сохранение датафрейма\n",
        "df_Chat[\"Дата\"] = pd.to_datetime(df_Chat[\"Дата\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
        "start_date = pd.Timestamp(\"2023-08-31\")\n",
        "end_date = pd.Timestamp(\"2023-10-01\")\n",
        "filtered_df = df_Chat[(df_Chat[\"Дата\"] >= start_date) & (df_Chat[\"Дата\"] <= end_date)]\n",
        "filtered_df.drop_duplicates(subset=['Ссылка'], inplace=True)\n",
        "filtered_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "# Обработка данных в многопоточной среде\n",
        "def process_link(args):\n",
        "    link, date = args\n",
        "    try:\n",
        "        response = requests.get(link)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        tags_elem = soup.find(\"div\", class_=\"post_tags_top\")\n",
        "        tags_text = \", \".join(tag.get_text() for tag in tags_elem.find_all(\"a\"))\n",
        "        author_elem = soup.find(\"div\", class_=\"article_meta\").find(\"a\", class_=\"article_author\")\n",
        "        author = author_elem.get_text() if author_elem else None\n",
        "        title_elem = soup.find(\"h1\")\n",
        "        title = title_elem.get_text() if title_elem else None\n",
        "        return {\n",
        "            \"Ссылка\": link,\n",
        "            \"Название статьи\": title,\n",
        "            \"Тэги\": tags_text,\n",
        "            \"Автор\": author,\n",
        "            \"Дата\": date\n",
        "        }\n",
        "    except TooManyRedirects:\n",
        "        print(f\"Слишком много редиректов для ссылки: {link}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке ссылки {link}: {e}\")\n",
        "        return None\n",
        "\n",
        "links_and_dates = zip(filtered_df['Ссылка'], filtered_df['Дата'])\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    results = list(executor.map(process_link, links_and_dates))\n",
        "\n",
        "results = [result for result in results if result is not None]\n",
        "df_with_additional_data = pd.DataFrame(results)\n",
        "df_with_additional_data.to_csv(\"df_final.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e0d448",
      "metadata": {
        "id": "66e0d448"
      },
      "outputs": [],
      "source": [
        "df_with_additional_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a6e29e",
      "metadata": {
        "id": "e6a6e29e"
      },
      "outputs": [],
      "source": [
        "#sep.csv содержит данные из гугл аналитики\n",
        "#(Страница, Просмотры страниц,\tУникальные просмотры страниц,\tСредняя длительность просмотра страницы, Входы, Показатель отказов, Процент выходов, Ценность страницы)\n",
        "df_read = pd.read_csv('sep.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dd1438",
      "metadata": {
        "id": "d1dd1438"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['Входы', 'Показатель отказов', 'Процент выходов', 'Ценность страницы']\n",
        "df_view_no_columns = df_read.drop(columns = columns_to_drop)\n",
        "df_view_no_columns.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9569d4b4",
      "metadata": {
        "id": "9569d4b4"
      },
      "outputs": [],
      "source": [
        "def add_prefix(value):\n",
        "    if isinstance(value, str):\n",
        "        return 'URL сайта' + value\n",
        "    return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d81c41",
      "metadata": {
        "id": "98d81c41"
      },
      "outputs": [],
      "source": [
        "df_view_no_columns['Страница'] = df_view_no_columns['Страница'].apply(lambda x: add_prefix(x))\n",
        "df_view_no_columns.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06be824",
      "metadata": {
        "id": "d06be824"
      },
      "outputs": [],
      "source": [
        "df_with_additional_data.rename(columns={'Ссылка': 'Страница'}, inplace=True)\n",
        "df_with_additional_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d34fb0d",
      "metadata": {
        "id": "6d34fb0d"
      },
      "outputs": [],
      "source": [
        "merge_df = df_with_additional_data.merge(df_view_no_columns, on='Страница')\n",
        "merge_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655cb925",
      "metadata": {
        "id": "655cb925"
      },
      "outputs": [],
      "source": [
        "sorted_df = merge_df.sort_values(by='Просмотры страниц', ascending=False)\n",
        "sorted_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49cf51d",
      "metadata": {
        "id": "d49cf51d"
      },
      "outputs": [],
      "source": [
        "merge_df.to_csv('result_table.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094a9c61",
      "metadata": {
        "id": "094a9c61"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}